#' @return A nested tibble in which each row contains an LDA model.
#' @usage old_par_fit_LDAs(dtms, k_opts = 2:3, iter_opts = 2000, coherence_n = 10)
#' @export
old_par_fit_LDAs <- function(dtms,
k_opts = 2:3,
iter_opts = 2000,
coherence_n = 10){
#Set up multicore session. Leave 1 core out of everything:
future::plan(future::multisession(workers = availableCores()-1))
# Set up tuning grid for LDA model
lda_tuning <- tidyr::expand_grid(k = k_opts,
alpha = 1,
delta = 1,
iter = iter_opts) %>%
dplyr::mutate(alpha = 1/k, delta = 0.1/k)
# Add tuning parameters for each query-source combo
lda_setup <- dtms %>%
dplyr::group_by(freq_cutoff) %>%
dplyr::mutate(lda_tuning = list(lda_tuning)) %>%
dplyr::ungroup() %>%
tidyr::unnest(cols = lda_tuning)
# Define function to run LDA for different values of k
run_lda <- function(dtm, k, alpha, delta, iter) {
topicmodels::LDA(x = dtm,
method = "Gibbs",
k = k,
control = list(seed = 1,
iter = iter,
alpha = alpha,
delta = delta))
}
options(future.rng.onMisuse = "ignore")
# Fit
lda <-lda_setup %>%
dplyr::mutate(lda = furrr::future_pmap(.l = list(dtm = dtm,
k = k,
alpha = alpha,
delta = delta,
iter = iter),
.f = run_lda), seed = TRUE, .progress = TRUE) %>%
dplyr::select(data, dtm, freq_cutoff, n_terms, n_docs, k, alpha, delta, iter, lda)
#Add coherence function to LDAs
.get_coherence <- function(dtm, lda, M = 10) {
dtm_matrix <- Matrix::sparseMatrix(i=dtm$i,
j=dtm$j,
x=dtm$v,
dims=c(dtm$nrow, dtm$ncol),
dimnames = dtm$dimnames)
phi <-  lda %>%
generics::tidy(matrix = "beta") %>%
tidyr::pivot_wider(names_from = "term", values_from = "beta",
names_repair = "minimal") %>%
dplyr::select(-topic) %>%
as.matrix()
coherence <- textmineR::CalcProbCoherence(phi,
dtm_matrix,
M = coherence_n)
topic <- paste("topic_", as.character((1:length(coherence))), sep = "")
#return
tibble::tibble(topic, coherence)
}
# future:::ClusterRegistry("stop")
#No need to use furrr::future_map2() here as it's unstable and calc is quick.
lda %>%
dplyr::mutate(coherence = purrr::map2(.x = dtm,
.y = lda,
.f = .get_coherence,
M = M))
}
ldas <- old_par_fit_LDAs(dtms, k_opts = 3, iter_opts = 20)
ldas <- old_par_fit_LDAs(dtms, k_opts = 3:6, iter_opts = 200)
topicmodels::LDA
ldas <- old_par_fit_LDAs(dtms, k_opts = 3:6, iter_opts = 2000)
rm(list=ls())
#' Function does not implicitly clean the text variable like `make_DTMs`
#'
#' @param df A data frame or tibble where each row is a separate post.
#' @param text_var The variable containing the text which you want to explore.
#' @param min_freq The minimum number of times a term must be observed to be considered.
#'
#' @return A nested tibble in which each row contains a document-term matrix.
#'
#' @export
#'
make_DTMs_parallel <- function(df,
text_var,
min_freq = 10,
hashtags = FALSE,
mentions = FALSE) {
future::plan(future::multisession(workers = future::availableCores() -1))
library(progressr)
handlers(global = TRUE)
# Clean the text - this part was edited by Jack to avoid mismatching document IDs (Mar 28th 2022)
clean_df <- df %>%
tibble::rowid_to_column(var = "message_id") %>%
dplyr::mutate(row_id = dplyr::row_number(),
cuts = base::cut(row_id, 7)) %>%
dplyr::mutate(message = {{text_var}}) %>%
dplyr::select(message, message_id, cuts) %>%
dplyr::filter(!is.na(message))%>%
dplyr::mutate(message_id = as.character(message_id))
## Create dtms ----
# 'Tuning parameters' for dtm creation
dtm_tuning <- tidyr::expand_grid(freq_cutoff = min_freq)
# Add freq cut-offs for each query-source combo
dtm_setup <- clean_df %>%
tidyr::nest(data = tidyr::everything()) %>%
dplyr::mutate(dtm_tuning = list(dtm_tuning)) %>%
tidyr::unnest(cols = dtm_tuning)
# Define function for creating dtm from tibble
create_dtm <- function(data, term_n) {
p <- along(data)
stopwords <- SegmentR::stopwords
term_counts <- data %>%
dplyr::group_split(cuts) %>%
furrr::future_map_dfr(~ .x %>%
# Split posts into individual words
tidytext::unnest_tokens(input = message,
output = word,
token = "tweets") %>%
# Remove boring words
dplyr::filter(!word %in% stopwords) %>%
# Remove words which don't appear frequently
dplyr::count(message_id, word, name = "term_freq")
) %>%
dplyr::group_by(word) %>%
dplyr::filter(sum(term_freq) > term_n) %>%
dplyr::ungroup()
# If no terms exceed required threshold
if (nrow(term_counts) == 0) {
return(NA)
} # This stops error but don't know why, seem to be no NULL entries in output
# Create dtm using calculated frequencies
term_counts %>%
tidytext::cast_dtm(document = message_id, term = word, value = term_freq)
}
future::plan(future::sequential())
# Create dtms using different freq cutoffs
dtm_setup %>%
dplyr::mutate(dtm = purrr::map2(.x = data, .y = freq_cutoff, create_dtm),
n_terms = purrr::map_dbl(dtm, ncol),
n_docs = purrr::map_dbl(dtm, nrow))
}
data <- ParseR::sprinklr_export %>%
janitor::clean_names()
dtms <- make_DTMs_parallel(data, message, min_freq = c(10, 20, 30))
#' Function does not implicitly clean the text variable like `make_DTMs`
#'
#' @param df A data frame or tibble where each row is a separate post.
#' @param text_var The variable containing the text which you want to explore.
#' @param min_freq The minimum number of times a term must be observed to be considered.
#'
#' @return A nested tibble in which each row contains a document-term matrix.
#'
#' @export
#'
make_DTMs_parallel <- function(df,
text_var,
min_freq = 10,
hashtags = FALSE,
mentions = FALSE) {
future::plan(future::multisession(workers = future::availableCores() -1))
library(progressr)
handlers(global = TRUE)
# Clean the text - this part was edited by Jack to avoid mismatching document IDs (Mar 28th 2022)
clean_df <- df %>%
tibble::rowid_to_column(var = "message_id") %>%
dplyr::mutate(row_id = dplyr::row_number(),
cuts = base::cut(row_id, 7)) %>%
dplyr::mutate(message = {{text_var}}) %>%
dplyr::select(message, message_id, cuts) %>%
dplyr::filter(!is.na(message))%>%
dplyr::mutate(message_id = as.character(message_id))
## Create dtms ----
# 'Tuning parameters' for dtm creation
dtm_tuning <- tidyr::expand_grid(freq_cutoff = min_freq)
# Add freq cut-offs for each query-source combo
dtm_setup <- clean_df %>%
tidyr::nest(data = tidyr::everything()) %>%
dplyr::mutate(dtm_tuning = list(dtm_tuning)) %>%
tidyr::unnest(cols = dtm_tuning)
# Define function for creating dtm from tibble
create_dtm <- function(data, term_n) {
p <- progressor(along = data)
stopwords <- SegmentR::stopwords
term_counts <- data %>%
dplyr::group_split(cuts) %>%
furrr::future_map_dfr(~ .x %>%
# Split posts into individual words
tidytext::unnest_tokens(input = message,
output = word,
token = "tweets") %>%
# Remove boring words
dplyr::filter(!word %in% stopwords) %>%
# Remove words which don't appear frequently
dplyr::count(message_id, word, name = "term_freq")
) %>%
dplyr::group_by(word) %>%
dplyr::filter(sum(term_freq) > term_n) %>%
dplyr::ungroup()
# If no terms exceed required threshold
if (nrow(term_counts) == 0) {
return(NA)
} # This stops error but don't know why, seem to be no NULL entries in output
# Create dtm using calculated frequencies
term_counts %>%
tidytext::cast_dtm(document = message_id, term = word, value = term_freq)
}
future::plan(future::sequential())
# Create dtms using different freq cutoffs
dtm_setup %>%
dplyr::mutate(dtm = purrr::map2(.x = data, .y = freq_cutoff, create_dtm),
n_terms = purrr::map_dbl(dtm, ncol),
n_docs = purrr::map_dbl(dtm, nrow))
}
dtms <- make_DTMs_parallel(data, message, min_freq = c(10, 20, 30))
#' Function does not implicitly clean the text variable like `make_DTMs`
#'
#' @param df A data frame or tibble where each row is a separate post.
#' @param text_var The variable containing the text which you want to explore.
#' @param min_freq The minimum number of times a term must be observed to be considered.
#'
#' @return A nested tibble in which each row contains a document-term matrix.
#'
#' @export
#'
make_DTMs_parallel <- function(df,
text_var,
min_freq = 10,
hashtags = FALSE,
mentions = FALSE) {
future::plan(future::multisession(workers = future::availableCores() -1))
library(progressr)
handlers(global = TRUE)
# Clean the text - this part was edited by Jack to avoid mismatching document IDs (Mar 28th 2022)
clean_df <- df %>%
tibble::rowid_to_column(var = "message_id") %>%
dplyr::mutate(row_id = dplyr::row_number(),
cuts = base::cut(row_id, 7)) %>%
dplyr::mutate(message = {{text_var}}) %>%
dplyr::select(message, message_id, cuts) %>%
dplyr::filter(!is.na(message))%>%
dplyr::mutate(message_id = as.character(message_id))
## Create dtms ----
# 'Tuning parameters' for dtm creation
dtm_tuning <- tidyr::expand_grid(freq_cutoff = min_freq)
# Add freq cut-offs for each query-source combo
dtm_setup <- clean_df %>%
tidyr::nest(data = tidyr::everything()) %>%
dplyr::mutate(dtm_tuning = list(dtm_tuning)) %>%
tidyr::unnest(cols = dtm_tuning)
# Define function for creating dtm from tibble
create_dtm <- function(data, term_n) {
p <- progressor(along = data)
stopwords <- SegmentR::stopwords
term_counts <- data %>%
dplyr::group_split(cuts) %>%
furrr::future_map_dfr(~ .x %>%
# Split posts into individual words
tidytext::unnest_tokens(input = message,
output = word,
token = "tweets") %>%
# Remove boring words
dplyr::filter(!word %in% stopwords) %>%
# Remove words which don't appear frequently
dplyr::count(message_id, word, name = "term_freq")
) %>%
dplyr::group_by(word) %>%
dplyr::filter(sum(term_freq) > term_n) %>%
dplyr::ungroup()
# If no terms exceed required threshold
if (nrow(term_counts) == 0) {
return(NA)
} # This stops error but don't know why, seem to be no NULL entries in output
# Create dtm using calculated frequencies
term_counts %>%
tidytext::cast_dtm(document = message_id, term = word, value = term_freq)
}
# future::plan(future::sequential())
# Create dtms using different freq cutoffs
dtm_setup %>%
dplyr::mutate(dtm = purrr::map2(.x = data, .y = freq_cutoff, create_dtm),
n_terms = purrr::map_dbl(dtm, ncol),
n_docs = purrr::map_dbl(dtm, nrow))
}
dtms <- make_DTMs_parallel(data, message, min_freq = c(10, 20, 30))
#' Function does not implicitly clean the text variable like `make_DTMs`
#'
#' @param df A data frame or tibble where each row is a separate post.
#' @param text_var The variable containing the text which you want to explore.
#' @param min_freq The minimum number of times a term must be observed to be considered.
#'
#' @return A nested tibble in which each row contains a document-term matrix.
#'
#' @export
#'
make_DTMs_parallel <- function(df,
text_var,
min_freq = 10,
hashtags = FALSE,
mentions = FALSE) {
future::plan(future::multisession(workers = future::availableCores() -1))
library(progressr)
handlers(global = TRUE)
# Clean the text - this part was edited by Jack to avoid mismatching document IDs (Mar 28th 2022)
clean_df <- df %>%
tibble::rowid_to_column(var = "message_id") %>%
dplyr::mutate(row_id = dplyr::row_number(),
cuts = base::cut(row_id, 7)) %>%
dplyr::mutate(message = {{text_var}}) %>%
dplyr::select(message, message_id, cuts) %>%
dplyr::filter(!is.na(message))%>%
dplyr::mutate(message_id = as.character(message_id))
## Create dtms ----
# 'Tuning parameters' for dtm creation
dtm_tuning <- tidyr::expand_grid(freq_cutoff = min_freq)
# Add freq cut-offs for each query-source combo
dtm_setup <- clean_df %>%
tidyr::nest(data = tidyr::everything()) %>%
dplyr::mutate(dtm_tuning = list(dtm_tuning)) %>%
tidyr::unnest(cols = dtm_tuning)
# Define function for creating dtm from tibble
create_dtm <- function(data, term_n) {
p <- progressor(along = data)
Sys.sleep(6.0-x)
p(sprintf("x=%g", x))
stopwords <- SegmentR::stopwords
term_counts <- data %>%
dplyr::group_split(cuts) %>%
furrr::future_map_dfr(~ .x %>%
# Split posts into individual words
tidytext::unnest_tokens(input = message,
output = word,
token = "tweets") %>%
# Remove boring words
dplyr::filter(!word %in% stopwords) %>%
# Remove words which don't appear frequently
dplyr::count(message_id, word, name = "term_freq")
) %>%
dplyr::group_by(word) %>%
dplyr::filter(sum(term_freq) > term_n) %>%
dplyr::ungroup()
# If no terms exceed required threshold
if (nrow(term_counts) == 0) {
return(NA)
} # This stops error but don't know why, seem to be no NULL entries in output
# Create dtm using calculated frequencies
term_counts %>%
tidytext::cast_dtm(document = message_id, term = word, value = term_freq)
}
# future::plan(future::sequential())
# Create dtms using different freq cutoffs
dtm_setup %>%
dplyr::mutate(dtm = purrr::map2(.x = data, .y = freq_cutoff, create_dtm),
n_terms = purrr::map_dbl(dtm, ncol),
n_docs = purrr::map_dbl(dtm, nrow))
}
dtms <- make_DTMs_parallel(data, message, min_freq = c(10, 20, 30))
#' Function does not implicitly clean the text variable like `make_DTMs`
#'
#' @param df A data frame or tibble where each row is a separate post.
#' @param text_var The variable containing the text which you want to explore.
#' @param min_freq The minimum number of times a term must be observed to be considered.
#'
#' @return A nested tibble in which each row contains a document-term matrix.
#'
#' @export
#'
make_DTMs_parallel <- function(df,
text_var,
min_freq = 10,
hashtags = FALSE,
mentions = FALSE) {
future::plan(future::multisession(workers = future::availableCores() -1))
library(progressr)
handlers(global = TRUE)
# Clean the text - this part was edited by Jack to avoid mismatching document IDs (Mar 28th 2022)
clean_df <- df %>%
tibble::rowid_to_column(var = "message_id") %>%
dplyr::mutate(row_id = dplyr::row_number(),
cuts = base::cut(row_id, 7)) %>%
dplyr::mutate(message = {{text_var}}) %>%
dplyr::select(message, message_id, cuts) %>%
dplyr::filter(!is.na(message))%>%
dplyr::mutate(message_id = as.character(message_id))
## Create dtms ----
# 'Tuning parameters' for dtm creation
dtm_tuning <- tidyr::expand_grid(freq_cutoff = min_freq)
# Add freq cut-offs for each query-source combo
dtm_setup <- clean_df %>%
tidyr::nest(data = tidyr::everything()) %>%
dplyr::mutate(dtm_tuning = list(dtm_tuning)) %>%
tidyr::unnest(cols = dtm_tuning)
# Define function for creating dtm from tibble
create_dtm <- function(data, term_n) {
p <- progressor(along = data)
Sys.sleep(6.0-data)
p(sprintf("data=%g", data))
stopwords <- SegmentR::stopwords
term_counts <- data %>%
dplyr::group_split(cuts) %>%
furrr::future_map_dfr(~ .x %>%
# Split posts into individual words
tidytext::unnest_tokens(input = message,
output = word,
token = "tweets") %>%
# Remove boring words
dplyr::filter(!word %in% stopwords) %>%
# Remove words which don't appear frequently
dplyr::count(message_id, word, name = "term_freq")
) %>%
dplyr::group_by(word) %>%
dplyr::filter(sum(term_freq) > term_n) %>%
dplyr::ungroup()
# If no terms exceed required threshold
if (nrow(term_counts) == 0) {
return(NA)
} # This stops error but don't know why, seem to be no NULL entries in output
# Create dtm using calculated frequencies
term_counts %>%
tidytext::cast_dtm(document = message_id, term = word, value = term_freq)
}
# future::plan(future::sequential())
# Create dtms using different freq cutoffs
dtm_setup %>%
dplyr::mutate(dtm = purrr::map2(.x = data, .y = freq_cutoff, create_dtm),
n_terms = purrr::map_dbl(dtm, ncol),
n_docs = purrr::map_dbl(dtm, nrow))
}
dtms <- make_DTMs_parallel(data, message, min_freq = c(10, 20, 30))
#' Function does not implicitly clean the text variable like `make_DTMs`
#'
#' @param df A data frame or tibble where each row is a separate post.
#' @param text_var The variable containing the text which you want to explore.
#' @param min_freq The minimum number of times a term must be observed to be considered.
#'
#' @return A nested tibble in which each row contains a document-term matrix.
#'
#' @export
#'
make_DTMs_parallel <- function(df,
text_var,
min_freq = 10,
hashtags = FALSE,
mentions = FALSE) {
future::plan(future::multisession(workers = future::availableCores() -1))
library(progressr)
handlers(global = TRUE)
# Clean the text - this part was edited by Jack to avoid mismatching document IDs (Mar 28th 2022)
clean_df <- df %>%
tibble::rowid_to_column(var = "message_id") %>%
dplyr::mutate(row_id = dplyr::row_number(),
cuts = base::cut(row_id, 7)) %>%
dplyr::mutate(message = {{text_var}}) %>%
dplyr::select(message, message_id, cuts) %>%
dplyr::filter(!is.na(message))%>%
dplyr::mutate(message_id = as.character(message_id))
## Create dtms ----
# 'Tuning parameters' for dtm creation
dtm_tuning <- tidyr::expand_grid(freq_cutoff = min_freq)
# Add freq cut-offs for each query-source combo
dtm_setup <- clean_df %>%
tidyr::nest(data = tidyr::everything()) %>%
dplyr::mutate(dtm_tuning = list(dtm_tuning)) %>%
tidyr::unnest(cols = dtm_tuning)
# Define function for creating dtm from tibble
create_dtm <- function(data, term_n) {
p <- progressor(along = data)
Sys.sleep(6.0-data)
# p(sprintf("data=%g", data))
stopwords <- SegmentR::stopwords
term_counts <- data %>%
dplyr::group_split(cuts) %>%
furrr::future_map_dfr(~ .x %>%
# Split posts into individual words
tidytext::unnest_tokens(input = message,
output = word,
token = "tweets") %>%
# Remove boring words
dplyr::filter(!word %in% stopwords) %>%
# Remove words which don't appear frequently
dplyr::count(message_id, word, name = "term_freq")
) %>%
dplyr::group_by(word) %>%
dplyr::filter(sum(term_freq) > term_n) %>%
dplyr::ungroup()
# If no terms exceed required threshold
if (nrow(term_counts) == 0) {
return(NA)
} # This stops error but don't know why, seem to be no NULL entries in output
# Create dtm using calculated frequencies
term_counts %>%
tidytext::cast_dtm(document = message_id, term = word, value = term_freq)
}
# future::plan(future::sequential())
# Create dtms using different freq cutoffs
dtm_setup %>%
dplyr::mutate(dtm = purrr::map2(.x = data, .y = freq_cutoff, create_dtm),
n_terms = purrr::map_dbl(dtm, ncol),
n_docs = purrr::map_dbl(dtm, nrow))
}
dtms <- make_DTMs_parallel(data, message, min_freq = c(10, 20, 30))
document()
library(devtools)
library(roxygen2)
#roxygenise(clean = TRUE)
document()
document()
rm(list=ls())
document()
check()
library(JPackage)
